<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://duzexu.github.io</id>
    <title>肚肚的小窝</title>
    <updated>2024-03-02T08:17:51.963Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://duzexu.github.io"/>
    <link rel="self" href="https://duzexu.github.io/atom.xml"/>
    <subtitle>Talk is cheap, Show me the code.</subtitle>
    <logo>https://duzexu.github.io/images/avatar.png</logo>
    <icon>https://duzexu.github.io/favicon.ico</icon>
    <rights>All rights reserved 2024, 肚肚的小窝</rights>
    <entry>
        <title type="html"><![CDATA[GitHub 开发者如何领取 StarkNet 空投]]></title>
        <id>https://duzexu.github.io/post/github-starknet/</id>
        <link href="https://duzexu.github.io/post/github-starknet/">
        </link>
        <updated>2024-03-02T06:31:50.000Z</updated>
        <summary type="html"><![CDATA[<p>快看看你能不能领到111.1 枚价值 200 美金的 STRK 币</p>
]]></summary>
        <content type="html"><![CDATA[<p>快看看你能不能领到111.1 枚价值 200 美金的 STRK 币</p>
<!-- more -->
<p>这几天，StartNet 发放了一笔空投，如果您是 GitHub 开发者，并且在 2023 年 11 月 15 日之前，您至少向全球星级排名前 5,000 位的版本库提交了三次内容。其中至少一次提交发生在 2018 年或之后。</p>
<p>这是英文原文：</p>
<blockquote>
<p>You made at least three commits to a repository that is one of the top 5,000 repositories worldwide, ranked by number of stars, before November 15th, 2023. At least one of these commits occurred during 2018 or later.</p>
</blockquote>
<p>那么您应该可以领取一笔空投，本文教您如何领取 StarkNet 空投。</p>
<h3 id="确认自己可以领取多少个-strk">确认自己可以领取多少个 STRK</h3>
<p>打开这个链接：https://provisions.starknet.io/</p>
<p><img src="https://duzexu.github.io/post-images/1709363096861.png" alt="" loading="lazy"><br>
<img src="https://duzexu.github.io/post-images/1709363102401.png" alt="" loading="lazy"></p>
<p>在网页的这个框中按图示上图操作</p>
<p><img src="https://duzexu.github.io/post-images/1709363510864.png" alt="" loading="lazy"><br>
<img src="https://duzexu.github.io/post-images/1709363515835.png" alt="" loading="lazy"></p>
<p>然后我们可以看到，我可以领取 111.1 个 STRK</p>
<p>也可以点进下面两个连接直接用你的GitHub昵称搜索<br>
<a href="https://raw.githubusercontent.com/starknet-io/provisions-data/main/github/github-0.json">github-0.json</a><br>
<a href="https://raw.githubusercontent.com/starknet-io/provisions-data/main/github/github-1.json">github-1.json</a></p>
<p>如果不在名单里，只能多多贡献开源社区，等待下一次空投了👻</p>
<h3 id="领取空投">领取空投</h3>
<p>领取空投之前，首先需要安装钱包，安装 Argent X 或者 Braavos 钱包，直接在各个浏览器插件市场搜索即可，比如 Chrome 的 <a href="https://chromewebstore.google.com/detail/argent-x-starknet-wallet/dlcobpjiigpikoobohmabehhmhfoodbb">Argent X</a> 和<a href="https://chromewebstore.google.com/detail/braavos-smart-wallet/jnlgamecbpmbajjfhmmmlhejkemejdma">Braavos</a>插件<br>
<img src="https://duzexu.github.io/post-images/1709364480505.png" alt="" loading="lazy"><br>
然后在钱包中创建一个新的钱包</p>
<p><img src="https://duzexu.github.io/post-images/1709364655664.png" alt="" loading="lazy"><br>
<img src="https://duzexu.github.io/post-images/1709364664031.png" alt="" loading="lazy"></p>
<p>创建后钱包之后，按上图操作</p>
<p><img src="https://duzexu.github.io/post-images/1709364683636.png" alt="" loading="lazy"><br>
<img src="https://duzexu.github.io/post-images/1709364775174.png" alt="" loading="lazy"></p>
<p>接着选择自己的钱包，然后登录 GitHub 账号</p>
<p><img src="https://duzexu.github.io/post-images/1709364791757.png" alt="" loading="lazy"><br>
<img src="https://duzexu.github.io/post-images/1709364798286.png" alt="" loading="lazy"></p>
<p>之后会答几道题，跟 Web3 相关，非常简单，不用担心，答完题后就会 StartNet 就会通过链上转账转到你的钱包当中<br>
<img src="https://duzexu.github.io/post-images/1709364858815.png" alt="" loading="lazy"><br>
稍等片刻即可，上图就是领取成功的界面，此时可以看到你的Braavos钱包中有了111.1枚STRK币<br>
<img src="https://duzexu.github.io/post-images/1709365114894.png" alt="" loading="lazy"></p>
<h3 id="如何提币">如何提币</h3>
<p>这里会介绍通过<a href="https://www.binance.com/">Binance（币安）</a>提到交易所的方式，当然还有别的交易所也是可以的</p>
<p>Binance 可以通过「链上充币」的方式将 $STRK 充到 Binance 上，然后出售换成 USDT，再通过交易所 C2C，可以将 USDT 换成 CNY，以下是详细步骤</p>
<p>在 Binance 网页版中：</p>
<p><img src="https://duzexu.github.io/post-images/1709365296906.png" alt="" loading="lazy"><br>
<img src="https://duzexu.github.io/post-images/1709365305602.png" alt="" loading="lazy"></p>
<p>选择「充值加密货币」</p>
<p><img src="https://duzexu.github.io/post-images/1709365314224.png" alt="" loading="lazy"><br>
<img src="https://duzexu.github.io/post-images/1709365440132.png" alt="" loading="lazy"></p>
<p>然后选择 STRK，就可以得到充值地址，然后在钱包中往这个地址转账即可，转账完成需要稍等十分钟，确认完成就能在Binance钱包看到了</p>
<figure data-type="image" tabindex="1"><img src="https://duzexu.github.io/post-images/1709366629118.jpg" alt="" loading="lazy"></figure>
<p>在将币充值到 Binance 之后，售出变成 USDT，然后就可以通过交易所 C2C 的方式，将 USDT 转换成 CNY</p>
<h3 id="为什么-starknet-要发放空投">为什么 StarkNet 要发放空投</h3>
<ul>
<li>激励更多开发者参与开源项目：通过对开源项目贡献者进行代币空投，Web3 项目能够激励更多的开发者参与到开源项目中。这种激励机制能够吸引那些可能对开源贡献感到犹豫的开发者，因为它提供了一个即时的、有形的奖励。随着更多的开发者投入到开源项目中，这些项目的发展速度和质量都将得到提升。<br>
促进 Web3 技术的普及和理解：对于许多传统的开发者来说，Web3 仍然是一个相对陌生的概念。通过将 Web3 项目与开源社区结合起来，可以帮助传统开发者更容易地了解和接触到区块链和加密货币相关的技术。这种跨界合作有助于加速 Web3 技术的普及和理解，同时也为开源项目引入了新的视角和技术解决方案。</li>
<li>增加开源项目的可持续性：开源项目的可持续性一直是一个挑战，因为许多项目依赖于志愿者的贡献和赞助。通过代币空投，Web3 项目可以为开源贡献者提供一种新的收入来源，增加项目的吸引力和可持续性。这种财务激励也可能鼓励更多的人投入到项目的长期维护和发展中。</li>
<li>建立更紧密的社区联系：空投活动能够帮助建立和加强 Web3 项目与开源社区之间的联系。通过对开源贡献者的奖励，Web3 项目可以展示它们对社区的支持和承诺，从而建立起更强的社区信任和忠诚度。这种紧密的联系不仅有助于项目的长期成功，也为开源贡献者提供了更多的参与和影响项目发展的机会。<br>
鼓励创新和实验：最后，对开源项目贡献者进行空投是一种鼓励创新和实验的方式。它提供了一种机制，奖励那些愿意尝试新技术和解决方案的开发者。这种鼓励可以推动技术的快速发展，促进新的解决方案和应用的产生。</li>
</ul>
<p>总而言之，STRK 给知名 GitHub 项目贡献者进行空投不仅是对这些贡献者的肯定，也是推动开源和Web3 生态系统发展的一种创新方式。这种跨界合作的模式为其他项目提供了一个值得学习的榜样，预示着未来可能会有更多类似的活动，为整个技术社区带来正面的影响。</p>
<blockquote>
<p>如果您觉得本篇文章对您有帮助的话，您可以转几个 $STRK 给我助我买一杯咖啡，我的钱包地址是：0x015e611ea96a4dac62694a3df55341b182d57dfc09f90193cb9447b1128401ae</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unity3D 跨平台通信]]></title>
        <id>https://duzexu.github.io/post/unity3d-cross-flatform/</id>
        <link href="https://duzexu.github.io/post/unity3d-cross-flatform/">
        </link>
        <updated>2022-11-22T07:35:38.000Z</updated>
        <summary type="html"><![CDATA[<p>本文介绍Unity和iOS和Windows通信</p>
]]></summary>
        <content type="html"><![CDATA[<p>本文介绍Unity和iOS和Windows通信</p>
<!-- more -->
<h3 id="1-unity与c交互">1. Unity与C++交互</h3>
<p>Windows平台的SDK是C++编写的DLL库，所以我们需要Unity和C++进行通信</p>
<h4 id="11-基本概念">1.1 基本概念</h4>
<ul>
<li>托管(Managed)和非托管(Unmanaged)：.Net的运行环境是CLR(Common Language Runtime)，运行在CLR上的代码成为托管代码(Managed Code)，CLR提供了自动的垃圾回收机制(GC)。而C++是编译后直接由操作系统执行的代码，不运行在CLR上，所以C++属于非托管代码(Unmanaged Code)。</li>
<li>P/Invoke：P/Invoke（Platform Invoke，平台调用）使得我们可以在托管代码中调用非托管函数，Unity与C++的交互都是通过P/Invoke实现。（[DllImport]）</li>
</ul>
<h4 id="12-创建wrapper层c-dll">1.2 创建Wrapper层C++ DLL</h4>
<p>在VS中新建DLL项目，把引用的IM和RTC库拖入项目，在项目属性中设置好*.dll.lib链接地址以及头文件链接地址（如下图）<br>
<img src="https://duzexu.github.io/post-images/1669109075965.PNG" alt="" loading="lazy"><br>
<img src="https://duzexu.github.io/post-images/1669109190019.PNG" alt="" loading="lazy"><br>
<img src="https://duzexu.github.io/post-images/1669109197157.PNG" alt="" loading="lazy"><br>
<img src="https://duzexu.github.io/post-images/1669109202942.PNG" alt="" loading="lazy"><br>
新建一个类RTCInterface.h和RTCInterface.cpp</p>
<pre><code class="language-c++">//RTCInterface.h

extern &quot;C&quot;
{
    __declspec(dllexport) RCRTCEngine *rcrtc_create_engine(void* im_client);
    //__declspec(dllexport)必须添加
}
</code></pre>
<pre><code class="language-c++">//RTCInterface.cpp
#include &quot;RTCInterface.h&quot;

extern &quot;C&quot;
{
    RCRTCEngine *rcrtc_create_engine(void* im_client)
    {
        //code...
    }
}
</code></pre>
<h4 id="13-c调用">1.3 C#调用</h4>
<p>右键项目生成DLL后，将生成的DLL以及依赖的DLL拷贝到Unity项目对应架构的目录中，设置好对应的架构<br>
<img src="https://duzexu.github.io/post-images/1669109332762.PNG" alt="" loading="lazy"></p>
<p>在Unity中新建NativeWin.cs脚本</p>
<pre><code class="language-c#">//NativeWin.cs
namespace cn_rongcloud_rtc_unity
{
    internal class NativeWin
    {
        [DllImport(&quot;RTCWinWapper&quot;, CharSet = CharSet.Ansi, CallingConvention = CallingConvention.Cdecl)]
        internal static extern IntPtr rcrtc_create_engine(IntPtr client);
        //DllImport后面的名称需要和引入的DLL名称一致
    }
}
</code></pre>
<p>这样在C#中调用NativeWin的create方法就可以调用到C++的代码了</p>
<h4 id="14-其他情况">1.4 其他情况</h4>
<ul>
<li>参数中有类</li>
</ul>
<p>需要在C#和Wrapper中声明对应的结构体，C#端将C#类转为结构体，Wrapper中将结构体转为C++类</p>
<pre><code class="language-c#">//声明结构体
[StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
internal struct rtc_engine_setup
{
    [MarshalAs(UnmanagedType.U1)] 
    public bool reconnectable;

    public int statsReportInterval;

    [MarshalAs(UnmanagedType.U1)] 
    public bool enableSRTP;
    public IntPtr audioSetup;
    public IntPtr videoSetup;
    public string mediaUrl;
    public string logPath;
}

//声明方法
[DllImport(&quot;RTCWinWapper&quot;, CharSet = CharSet.Ansi, CallingConvention = CallingConvention.Cdecl)]
internal static extern IntPtr rcrtc_create_engine_with_setup(IntPtr client, ref rtc_engine_setup setup);

//调用方法
internal RCRTCEngineWin(RCRTCEngineSetup setup)
{
    //转换成结构体
    rtc_engine_setup cobject;
    cobject.reconnectable = setup.IsReconnectable();
    if (setup.GetAudioSetup() != null)
    {
        rtc_audio_setup audio;
        audio.audioCodecType = (int)setup.GetAudioSetup().GetAudioCodecType();
        IntPtr ptr = Marshal.AllocHGlobal(Marshal.SizeOf(audio));
        Marshal.StructureToPtr(audio, ptr, true);
        cobject.audioSetup = ptr;
     }
     else
     {
         cobject.audioSetup = IntPtr.Zero;
     }
     //other paramers...
     
     //调用方法
     rtc_engine = NativeWin.rcrtc_create_engine_with_setup(im_client, ref cobject);
     if (cobject.audioSetup != IntPtr.Zero)
     {
        Marshal.FreeHGlobal(cobject.audioSetup);
     }
}
</code></pre>
<p>注意：<br>
结构体中有Bool需要指定非托管类型为UnmanagedType.U1,可以告知运行时将字段作为 1 字节本机 bool 类型进行封送<br>
结构体中有其他的类需要使用Marshal.AllocHGlobal在非托管内存中分配内存，使用结束后需手动调用Marshal.FreeHGlobal释放</p>
<pre><code class="language-c++">//RTCInterface.cpp
#include &quot;RTCInterface.h&quot;

extern &quot;C&quot;
{
    //声明结构体
    typedef struct rtc_engine_setup
    {
        bool reconnectable;
        int statsReportInterval;
        bool enableSRTP;
        rtc_audio_setup* audioSetup;
        rtc_video_setup* videoSetup;
        const char* mediaUrl;
        const char* logPath;
    } rtc_engine_setup;

    RCRTCEngine *rcrtc_create_engine_with_setup(void *im_client, rtc_engine_setup *csetup)
    {
        RCRTCEngineSetup *setup = RCRTCEngineSetup::create();
        setup-&gt;setEnableSRTP(csetup-&gt;enableSRTP);
        //other params...
        RCRTCEngine *engine = RCRTCEngine::create(im_client, setup);
        return engine;
    }
}
</code></pre>
<ul>
<li>回调Unity方法</li>
</ul>
<pre><code class="language-c#">//C#中声明回调
public delegate void OnRoomJoinedDelegate(int code, String errMsg);

//实现回调方法
[MonoPInvokeCallback(typeof(OnRoomJoinedDelegate))]
private static void on_rtc_room_joined(int code, string message)
{
    //code...
}

//声明调用方法
[DllImport(&quot;RTCWinWapper&quot;, CallingConvention = CallingConvention.Cdecl, CharSet = CharSet.Ansi)]
internal static extern void rcrtc_set_engine_listeners(OnRoomJoinedDelegate on_rtc_room_joined);

//设置回调 
NativeWin.rcrtc_set_engine_listeners(on_rtc_room_joined);
</code></pre>
<pre><code class="language-c++">extern &quot;C&quot;
{
    //wrapper中声明回调
    typedef void (*on_rtc_room_joined)(int code, const char* message);
    
    //声明调用方法
    void rcrtc_set_engine_listeners(on_rtc_room_joined _on_rtc_room_joined)
    {
        //直接调用
        _on_rtc_room_joined(0, &quot;error msg&quot;);
    }
}
</code></pre>
<h3 id="2-unity和ios交互">2. Unity和iOS交互</h3>
<p>Unity和iOS的交互和跟C++的交互过程基本一致，也是通过DllImport调用非托管函数</p>
<h4 id="21-创建wrapper层framework">2.1 创建Wrapper层framework</h4>
<p>新建Xcode framework项目,将使用的库拖入项目<br>
<img src="https://duzexu.github.io/post-images/1669110298035.PNG" alt="" loading="lazy"></p>
<p>新建一个交互类RongUnityRTC.mm</p>
<pre><code class="language-c++">//RongUnityRTC.mm

extern &quot;C&quot; {
    //声明结构体
    typedef struct rtc_engine_setup {
      bool reconnectable;
      int statsReportInterval;
      bool enableSRTP;
      rtc_audio_setup *audioSetup;
      rtc_video_setup *videoSetup;
      const char *mediaUrl;
    } rtc_engine_setup;
    
    //声明创建方法
    CFTypeRef rtc_create_engine_with_setup(rtc_engine_setup *csetup) {
      RCRTCIWEngineSetup *setup = [[RCRTCIWEngineSetup alloc] init];
      setup.enableSRTP = csetup-&gt;enableSRTP;
      if (csetup-&gt;audioSetup != NULL) {
        RCRTCIWAudioSetup *audioSetup = [[RCRTCIWAudioSetup alloc] init];
        audioSetup.type = (RCRTCIWAudioCodecType)csetup-&gt;audioSetup-&gt;audioCodecType;
        audioSetup.mixOtherAppsAudio = csetup-&gt;audioSetup-&gt;mixOtherAppsAudio;
        setup.audioSetup = audioSetup;
      }
      //other params...
      engine = [RCRTCIWEngine create:setup];
      return CFBridgingRetain(engine);
    }
    
    //声明回调
    typedef void (*on_rtc_room_joined)(int code, const char* message);
    
    //声明调用方法
    void rcrtc_set_engine_listeners(on_rtc_room_joined _on_rtc_room_joined)
    {
        //直接调用
        _on_rtc_room_joined(0, &quot;error msg&quot;);
    }
}
</code></pre>
<h4 id="22-c调用">2.2 C#调用</h4>
<p>Build wrapper项目，拷贝生成的framework以及依赖的frawork到Unity中，并设置好对应的架构<br>
<img src="https://duzexu.github.io/post-images/1669110428675.PNG" alt="" loading="lazy"><br>
在Unity中新建NativeIOS.cs脚本</p>
<pre><code class="language-c#">//NativeIOS.cs
namespace cn_rongcloud_rtc_unity
{
    //声明结构体
    [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
    internal struct rtc_engine_setup
    {
        [MarshalAs(UnmanagedType.U1)] 
        public bool reconnectable;

        public int statsReportInterval;

        [MarshalAs(UnmanagedType.U1)] 
        public bool enableSRTP;
        public IntPtr audioSetup;
        public IntPtr videoSetup;
        public string mediaUrl;
        public string logPath;
    }

    internal class NativeIOS
    {
        [DllImport(&quot;__Internal&quot;, CallingConvention = CallingConvention.Cdecl, CharSet = CharSet.Ansi)]
        internal static extern IntPtr rtc_create_engine_with_setup(ref rtc_engine_setup setup);
        //DllImport后面的名称必须为__Internal

        [DllImport(&quot;__Internal&quot;, CallingConvention = CallingConvention.Cdecl, CharSet = CharSet.Ansi)]
        internal static extern void rcrtc_set_engine_listeners(OnRoomJoinedDelegate on_rtc_room_joined)
    }
}

//C#中声明回调
public delegate void OnRoomJoinedDelegate(int code, String errMsg);

//实现回调方法
[MonoPInvokeCallback(typeof(OnRoomJoinedDelegate))]
private static void on_rtc_room_joined(int code, string message)
{
    //code...
}
</code></pre>
<p>调用跟C++一致</p>
<pre><code class="language-c#">//调用方法
internal RCRTCEngineIOS(RCRTCEngineSetup setup)
{
    //设置回调 
    NativeIOS.rcrtc_set_engine_listeners(on_rtc_room_joined);
    //转换成结构体
    rtc_engine_setup cobject;
    cobject.reconnectable = setup.IsReconnectable();
    if (setup.GetAudioSetup() != null)
    {
        rtc_audio_setup audio;
        audio.audioCodecType = (int)setup.GetAudioSetup().GetAudioCodecType();
        IntPtr ptr = Marshal.AllocHGlobal(Marshal.SizeOf(audio));
        Marshal.StructureToPtr(audio, ptr, true);
        cobject.audioSetup = ptr;
     }
     else
     {
         cobject.audioSetup = IntPtr.Zero;
     }
     //other paramers...
     
     //调用方法
     rtc_engine = NativeIOS.rcrtc_create_engine_with_setup(im_client, ref cobject);
     if (cobject.audioSetup != IntPtr.Zero)
     {
        Marshal.FreeHGlobal(cobject.audioSetup);
     }
}
</code></pre>
<h4 id="23-其他情况">2.3 其他情况</h4>
<ul>
<li>对象有继承关系</li>
</ul>
<p>c#为<code>ios_class_warpper</code>对象 , <code>type</code> 保存类名, <code>obj</code> 存真正的对象指针</p>
<pre><code class="language-c#">[StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
internal struct ios_class_warpper
{
    public IntPtr obj;
    public string type;
}

internal static ios_class_warpper toMessageWapper(RCIMMessage message)
{
    ios_class_warpper message_wapper;
    if (message is RCIMUnknownMessage)
    {
        im_unknown_message cmessage = toUnknownMessage((RCIMUnknownMessage)message);
        IntPtr message_ptr = Marshal.AllocHGlobal(Marshal.SizeOf(cmessage));
        Marshal.StructureToPtr(cmessage, message_ptr, false);
        message_wapper.obj = message_ptr;
        message_wapper.type = &quot;RCIMIWUnknownMessage&quot;;
    }
    else if (message is RCIMCustomMessage)
    {
        //...
    }
}
</code></pre>
<p>oc转换则是根据type初始化对应的对象</p>
<pre><code class="language-Objective-C">+ (RCIMIWMessage *)fromMessageWapper:(struct ios_class_warpper *)cmessage {
  if (cmessage == NULL || cmessage-&gt;obj == NULL || cmessage-&gt;type == NULL) {
    return nil;
  }
  RCIMIWMessage *message_wapper = nil;
  NSString *type = [NSString stringWithUTF8String:cmessage-&gt;type];
  if ([type isEqualToString:@&quot;RCIMIWUnknownMessage&quot;]) {
    message_wapper =
        [self fromUnknownMessage:(im_unknown_message *)cmessage-&gt;obj];
  }else if //...
 }
</code></pre>
<p>转换回来的过程则是相反的</p>
<ul>
<li>数组</li>
</ul>
<p>c#转为 ios_c_list对象，list存数组指针，count存数组数量</p>
<pre><code class="language-c#">[StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
internal struct ios_c_list
{
    public IntPtr list;
    public long count;
}

//转到ios
internal static IntPtr GetStructMapPointer&lt;StructType&gt;(ref List&lt;StructType&gt; clist)
{
     int size = Marshal.SizeOf(typeof(StructType));
     IntPtr list_ptr = Marshal.AllocHGlobal(clist.Count * size);
     for (int i = 0; i &lt; clist.Count; i++)
     {
          Marshal.StructureToPtr(clist[i], list_ptr+size*i, false);
     }
     ios_c_list map;
     map.list = list_ptr;
     map.count = clist.Count;
     IntPtr map_ptr = Marshal.AllocHGlobal(Marshal.SizeOf(typeof(ios_c_list)));
     Marshal.StructureToPtr(map, map_ptr, false);
     return map_ptr;
}
//从ios转回
internal static List&lt;StructType&gt; GetObjectListByPtr&lt;StructType&gt;(IntPtr ptr)
{
    if (ptr == IntPtr.Zero)
    {
        return new List&lt;StructType&gt;();
    }
    ios_c_list clist = Marshal.PtrToStructure&lt;ios_c_list&gt;(ptr);
    StructType[] cobjects = new StructType[clist.count];
    for (uint i = 0; i &lt; clist.count; ++i)
    {
       IntPtr item_ptr = new IntPtr(ptr.ToInt64() + Marshal.SizeOf(typeof(StructType)) * i);

       if ((item_ptr != null))
       {
           cobjects.Add((StructType)Marshal.PtrToStructure(item_ptr, typeof(StructType)));
       }
    }
    return new List&lt;StructType&gt;(cobjects);
}
</code></pre>
<p>oc根据count遍历</p>
<pre><code class="language-oc">typedef struct ios_c_list {
  void *list;
  unsigned long count;
} ios_c_list;
//从c#
ios_class_warpper *messages_iter = c_list-&gt;list;
for (int i = 0; i &lt; c_list-&gt;count; i++) {
    //   messages_iter ... 
    messages_iter++;
}
//转到c#
//NSArray&lt;RCIMIWMessage *&gt; *messages = ...
 ios_c_list *clist = (ios_c_list *)malloc(sizeof(ios_c_list));
 memset(clist, 0, sizeof(ios_c_list));
 ios_class_warpper *cmessages = (ios_class_warpper *)malloc(
          sizeof(ios_class_warpper) * messages.count);
 memset(cmessages, 0, sizeof(ios_class_warpper) * messages.count);
 ios_class_warpper *messages_iter = cmessages;
 for (int i = 0; i &lt; messages.count; i++) {
     [RongUnityConvert makeMessageWapper:messages[i] to:messages_iter];
     messages_iter++;
 }
 clist-&gt;list = cmessages;
 clist-&gt;count = messages.count;
 return clist;
</code></pre>
<ul>
<li>字符串数组</li>
</ul>
<p>和数组不同的点是字符串需要转换为指针，则结构就是指针数组</p>
<pre><code class="language-c#">//转到ios
internal static IntPtr GetStringListPointer(List&lt;string&gt; clist)
{
      IntPtr[] ptrArray = new IntPtr[clist.Count];
      for (int i = 0; i &lt; clist.Count; i++)
      {
          ptrArray[i] = Marshal.StringToHGlobalAnsi(clist[i]);
      }
      IntPtr list_ptr = Marshal.AllocHGlobal(Marshal.SizeOf(typeof(IntPtr)) * clist.Count);
      for (int j = 0; j &lt; clist.Count; j++)
      {
          IntPtr item_ptr = new IntPtr(list_ptr.ToInt64() + Marshal.SizeOf(typeof(IntPtr)) * j);
          Marshal.StructureToPtr(ptrArray[j], item_ptr, false);
      }
      ios_c_list map;
      map.list = list_ptr;
      map.count = clist.Count;
      IntPtr result_ptr = Marshal.AllocHGlobal(Marshal.SizeOf(typeof(ios_c_list)));
      Marshal.StructureToPtr(map, result_ptr, false);
      return result_ptr;
}
//从ios转回      
internal static List&lt;string&gt; GetStringListByPtr(IntPtr ptr)
{
    if (ptr == IntPtr.Zero)
    {
        return new List&lt;string&gt;();
    }
    ios_c_list clist = Marshal.PtrToStructure&lt;ios_c_list&gt;(ptr);
    List&lt;string&gt; cobjects = new List&lt;string&gt;();
    for (int i = 0; i &lt; clist.count; i++)
    {
        IntPtr item_ptr = new IntPtr(clist.list.ToInt64() + Marshal.SizeOf(typeof(IntPtr)) * i);
        IntPtr str_ptr = Marshal.PtrToStructure&lt;IntPtr&gt;(item_ptr);
        cobjects.Add(PtrToString(str_ptr));
    }
    return cobjects;
}
        
//需要注意释放
internal static void FreeStringListByPtr(IntPtr ptr)
{
     if (ptr == IntPtr.Zero)
     {
          return;
     }
     ios_c_list clist = Marshal.PtrToStructure&lt;ios_c_list&gt;(ptr);
     if (clist.list != IntPtr.Zero)
     {
         for (int i = 0; i &lt; clist.count; i++)
         {
             IntPtr item_ptr = new IntPtr(clist.list.ToInt64() + Marshal.SizeOf(typeof(IntPtr)) * i);
             IntPtr str_ptr = Marshal.PtrToStructure&lt;IntPtr&gt;(item_ptr);
             Marshal.FreeHGlobal(str_ptr);
         }
         Marshal.FreeHGlobal(clist.list);
     }
}
</code></pre>
<p>iOS接收采用<code>char*</code>数组接收</p>
<pre><code class="language-oc">//从c#
ios_c_list *clist = (ios_c_list *)cinfo-&gt;userIdList;
NSMutableArray&lt;NSString *&gt; *list =
        [[NSMutableArray alloc] initWithCapacity:clist-&gt;count];
char **iter = (char **)clist-&gt;list;
for (int i = 0; i &lt; clist-&gt;count; i++) {
  if (*iter != NULL) {
     [list addObject:[NSString stringWithUTF8String:*iter]];
  }
  iter++;
}
//从ios转回
//NSArray&lt;NSString *&gt; *keys = ...
ios_c_list *clist = (ios_c_list *)malloc(sizeof(ios_c_list));
memset(clist, 0, sizeof(ios_c_list));
char **cstrings = (char **)malloc(keys.count * sizeof(char *));
char **keys_iter = cstrings;
for (NSUInteger i = 0; i &lt; keys.count; i++) {
     NSString *string = keys[i];
     char *cstring = (char *)malloc(
            [string lengthOfBytesUsingEncoding:NSUTF8StringEncoding] + 1);
     strncpy(cstring, [string UTF8String],
                [string lengthOfBytesUsingEncoding:NSUTF8StringEncoding] + 1);
     *keys_iter = cstring;
     keys_iter++;
}
 clist-&gt;list = cstrings;
 clist-&gt;count = keys.count;
 return clist;
</code></pre>
<ul>
<li>字典</li>
</ul>
<p>转换为以<code>ios_c_map_item</code>为元素的数组</p>
<pre><code class="language-c#">[StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
internal struct ios_c_map_item
{
    public string key;
    public string value;
}
</code></pre>
<h4 id="24-内存管理">2.4 内存管理</h4>
<p>调用完成后<br>
c# 非托管的需要手动释放<br>
C malloc的内存需要free</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mac搭建STM32环境（基于Apple silicon）]]></title>
        <id>https://duzexu.github.io/post/stm32-in-mac/</id>
        <link href="https://duzexu.github.io/post/stm32-in-mac/">
        </link>
        <updated>2022-10-17T08:11:23.000Z</updated>
        <summary type="html"><![CDATA[<p>介绍如何在Mac上搭建STM32环境进行嵌入式开发</p>
]]></summary>
        <content type="html"><![CDATA[<p>介绍如何在Mac上搭建STM32环境进行嵌入式开发</p>
<!-- more -->
<h1 id="基本工具">基本工具</h1>
<h2 id="clion安装">Clion安装</h2>
<p>使用Homebrew安装</p>
<pre><code>brew install clion
</code></pre>
<p>或者<a href="https://www.jetbrains.com/zh-cn/clion/">官网下载</a></p>
<p>下载2022.1.13版本，下载破解包进行破解</p>
<h2 id="stm32cubemx安装">STM32Cubemx安装</h2>
<p>安装运行STM32Cubemx需要java环境<a href="https://www.java.com/zh-CN/">下载地址</a></p>
<p><a href="https://www.st.com/en/development-tools/stm32cubemx.html#get-software">官网下载地址</a>，该软件基于x86架构，在Apple silicon上运行需要rosetta2，若你的电脑没有安装，可以在终端输入<code>softwareupdate --install-rosetta</code>命令完成安装</p>
<p>下载好后解压，右键SetupSTM32CubeMX-6.5.0选择显示包内容，双击Contents/MacOs/SetupSTM32CubeMX-6_5_0即可进入安装界面，点击继续安装即可<br>
<img src="https://duzexu.github.io/post-images/1665995036880.jpg" alt="" loading="lazy"><br>
若显示无法打开，在系统偏好设置的安全性与隐私中允许打开该文件。</p>
<h2 id="openocd">openocd</h2>
<p>Apple silicon下载<a href="https://github.com/xpack-dev-tools/openocd-xpack/releases">该版本</a>，如图所示下载第一个。解压后储存在固定位置，我放在了/Library/xpack-openocd-0.11.0-3<br>
<img src="https://duzexu.github.io/post-images/1665995138130.webp" alt="" loading="lazy"></p>
<p>基于Intel的Mac可以直接通过homebrew安装</p>
<pre><code>brew install openocd
</code></pre>
<p>在终端输入<code>which openocd</code>查看命令可以查看安装位置</p>
<h2 id="xcode">xcode</h2>
<p>app store 搜索Xcode即可安装</p>
<h2 id="arm-gcc工具链">ARM-GCC工具链</h2>
<p>使用Homebrew安装</p>
<pre><code>brew tap ArmMbed/homebrew-formulae
brew install arm-none-eabi-gcc
</code></pre>
<p>安装后输入<code>arm-none-eabi-gcc -v</code>查看版本信息，有信息则安装成功</p>
<h2 id="环境配置">环境配置</h2>
<p>打开Clion，commend+,进入偏好设置</p>
<p>选择嵌入式开发，将软件路径输入，点击测试可以查看是否能够工作</p>
<p><img src="https://duzexu.github.io/post-images/1665995285616.webp" alt="" loading="lazy"><br>
插件安装<br>
<img src="https://duzexu.github.io/post-images/1665995290414.webp" alt="" loading="lazy"></p>
<p>参考<a href="https://zhuanlan.zhihu.com/p/145801160">配置CLion用于STM32开发【优雅の嵌入式开发】</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Android中录制和截取Unity屏幕]]></title>
        <id>https://duzexu.github.io/post/Record_Screen_In_Unity_For_Andriod/</id>
        <link href="https://duzexu.github.io/post/Record_Screen_In_Unity_For_Andriod/">
        </link>
        <updated>2022-04-02T09:42:17.000Z</updated>
        <summary type="html"><![CDATA[<p>这篇是之前<a href="https://duzexu.github.io/post/Record_Screen_In_Unity/">iOS中录制和截取Unity屏幕</a>的扩展，介绍如何在集成Unity的Android原生项目中截取和录制屏幕和声音</p>
]]></summary>
        <content type="html"><![CDATA[<p>这篇是之前<a href="https://duzexu.github.io/post/Record_Screen_In_Unity/">iOS中录制和截取Unity屏幕</a>的扩展，介绍如何在集成Unity的Android原生项目中截取和录制屏幕和声音</p>
<!-- more -->
<p>完整代码请查看<a href="https://github.com/duzexu/Record_Screen_In_Unity.git">Record_Screen_In_Unity</a></p>
<p>主要思路还是跟iOS一样，在Unity里获取当前屏幕截图，传给native,原生使用MediaCodec进行视频的合成</p>
<h3 id="1-准备工作">1. 准备工作</h3>
<p>我们还是使用之前的Unity项目，Unity端的采集方法不变，在<code>NativeInterface.cs</code>中添加安卓的接口。参考<a href="https://github.com/duzexu/Use-Unity-as-Library/blob/master/docs/android.md">Integrating Unity as a library into standard Android app</a>将Unity项目导出到AndroidBuild文件夹下并集成到原生工程中</p>
<blockquote>
<p>导出时模式选择<code>IL2CPP</code>模式时需要在<code>gradle.properties</code>文件中添加<em>unityStreamingAssets=.unity3d</em><br>
<img src="https://duzexu.github.io/post-images/1648894470716.png" alt="" loading="lazy"></p>
</blockquote>
<blockquote>
<p>修改unityLibrary的<code>build.gradle</code>文件，添加<code>implementation 'androidx.appcompat:appcompat:1.1.0'</code><br>
<img src="https://duzexu.github.io/post-images/1649214579099.png" alt="" loading="lazy"></p>
</blockquote>
<blockquote>
<p>将<code>UnityPlayerActivity</code>的父类由<code>Activity</code>修改为<code>AppCompatActivity</code><br>
<img src="https://duzexu.github.io/post-images/1649214711771.png" alt="" loading="lazy"></p>
</blockquote>
<h3 id="2视频帧和音频的传输">2.视频帧和音频的传输</h3>
<p>按照iOS的思路，安卓采用常规的<code>AndroidJavaClass.Call</code>的方式给原生传输视频帧，经过测试发现这种方式非常卡，出来的视频帧率还不到15，经过调研，采取c库中转的方式传输。使用CMake建立<code>RecordSDK</code>库，其中维护一个<code>TPCircularBuffer</code>，缓存最多三帧数据，Unity通过<code>copyVideoBuffer2Cyc</code>将数据传输给<code>TPCircularBuffer</code>缓存，安卓端通过一个循环询问是否有数据，如果有则通过<code>consumeVideoBuffer</code>获取，编码后通过<code>recycleVideoBuffer</code>释放这一帧数据，好接受新的视频帧。音频数据也是同样的原理。</p>
<h3 id="3-native端">3. Native端</h3>
<p>由于Unity采集的数据为<code>BGRA32</code>格式并且是垂直镜像的，将<code>KEY_COLOR_FORMAT</code>设置为<code>COLOR_Format32bitBGRA8888</code>后发现手机不支持这个颜色格式导致编码不成功，只能在c库接收数据时通过<code>libyuv</code>转成<code>nv21</code>格式，还要根据手机支持的颜色格式转成对应的yuv格式和镜像旋转。</p>
<pre><code class="language-java">//input为Camera预览格式NV21数据
if (mColorFormat == MediaCodecInfo.CodecCapabilities.COLOR_FormatYUV420SemiPlanar) {
    //nv21格式转为nv12格式
    Nv21ToNv12(input, yuvBuffer, mWidth, mHeight);
} else if (mColorFormat == MediaCodecInfo.CodecCapabilities.COLOR_FormatYUV420Planar) {
    //用于NV21格式转换为I420(YUV420P)格式
    Nv21ToI420(input, yuvBuffer, mWidth, mHeight);
} else if (mColorFormat == MediaCodecInfo.CodecCapabilities.COLOR_FormatYUV420PackedSemiPlanar) {
    System.arraycopy(input, 0, yuvBuffer, 0, mWidth * mHeight * 3 / 2);
}else if (mColorFormat == MediaCodecInfo.CodecCapabilities.COLOR_FormatYUV420PackedPlanar) {
    //用于NV21格式转换为YV12格式
    Nv21ToYv12(input, yuvBuffer, mWidth, mHeight);
}
MirrorYuv(yuvBuffer,mWidth,mHeight);
</code></pre>
<h3 id="4-音频录制">4. 音频录制</h3>
<p>音频采集和iOS端是一样的，不过经过测试，使用Unity原生的<code>VideoPlayer</code>在录制时视频播放声音会产生卡顿，并且在安卓端<code>VideoPlayer</code>的兼容性也不好，经常会因为视频有坏帧导视卡住，所以替换成了第三方的<code>AVPro Video</code>。</p>
<p>添加<code>MediaPlayer</code>组件进行播放，并且添加<code>AudioOutput</code>把声音通过<code>AudioSource</code>传输，这样我们就可以通过<code>OnAudioFilterRead(float[] data, int channels)</code>采集声音传给Native端，需要注意的是VideoApi需要选为<code>Exo Player</code>并且<code>Audio Output</code>为Unity<br>
<img src="https://duzexu.github.io/post-images/1648897605643.png" alt="" loading="lazy"></p>
<h3 id="参考">参考</h3>
<p><a href="https://github.com/duzexu/Use-Unity-as-Library/blob/master/docs/android.md">Integrating Unity as a library into standard Android app</a></p>
<p><a href="https://www.renderheads.com/content/docs/AVProVideo/articles/intro.html">AVPro Video Documentation</a></p>
<p>完整代码请查看<a href="https://github.com/duzexu/Record_Screen_In_Unity.git">Record_Screen_In_Unity</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[在iPhone上开发微信自动跳一跳插件]]></title>
        <id>https://duzexu.github.io/post/Auto-Jump-In-WeChat-Jump/</id>
        <link href="https://duzexu.github.io/post/Auto-Jump-In-WeChat-Jump/">
        </link>
        <updated>2020-08-17T09:59:46.000Z</updated>
        <summary type="html"><![CDATA[<p>现在已有的实现方法基本是PC端利用Python来实现的，还得安装很多工具，使用起来非常不方便，这篇文章介绍如何在iOS上利用原生客户端实现自动跳一跳，方便随时使用</p>
]]></summary>
        <content type="html"><![CDATA[<p>现在已有的实现方法基本是PC端利用Python来实现的，还得安装很多工具，使用起来非常不方便，这篇文章介绍如何在iOS上利用原生客户端实现自动跳一跳，方便随时使用</p>
<!-- more -->
<figure data-type="image" tabindex="1"><img src="https://duzexu.github.io/post-images/1597660201231.gif" alt="" loading="lazy"></figure>
<p>完整代码详见<a href="https://github.com/duzexu/WeChatHelper">WeChatHelper</a></p>
<h3 id="原理">原理</h3>
<p>和PC端实现原理一致，先用系统API进行屏幕截图，利用<a href="https://github.com/opencv/opencv">OpenCV</a>分析出棋子的位置和目标块的位置，计算出距离乘以系数后得出需要按压的时间，用<a href="https://github.com/devliubo/FTFakeTouch">FTFakeTouch</a>模拟相应的按压事件就行了</p>
<h3 id="如何进行不越狱插件开发">如何进行不越狱插件开发</h3>
<p>关于这部分，有很多相关的框架，例如<a href="https://github.com/Naituw/IPAPatch">IPAPatch</a>或者<a href="https://github.com/AloneMonkey/MonkeyDev">MonkeyDev</a>，这里就不在过多介绍了，可以参考相应的文章或者项目简介</p>
<h3 id="实现步骤">实现步骤</h3>
<h5 id="1搭建环境">1.搭建环境</h5>
<p>本例子采用的是<code>IPAPatch</code>，我们先取得微信的砸壳文件(自己砸壳或者从越狱渠道下载都行)，然后下载IPAPatch Demo工程，替换<code>Assets</code>文件夹下的app.iap为微信的iap砸壳文件，下载<code>OpenCV</code>代码编译为<code>opencv2.framework</code>添加入工程，下载<code>FTFakeTouch</code>工程编译成<code>FTFakeTouch.a</code>库添加入工程，新建<code>WeChatJumpManager</code>类添加入工程来作为我们实现相关功能的类，这样准备工作就完成了</p>
<h5 id="2触发方法">2.触发方法</h5>
<p>我们采用摇一摇的方式开启自动跳的功能，所以添加<code>UIWindow</code>的<code>Category</code>监听系统的摇一摇事件</p>
<pre><code>@implementation UIWindow (Shake)
-(void)motionEnded:(UIEventSubtype)motion withEvent:(UIEvent *)event {
    if (motion == UIEventSubtypeMotionShake) {
        //监听到摇动事件
    }
}
@end
</code></pre>
<h5 id="3截图">3.截图</h5>
<p>采用系统的截图方法</p>
<pre><code>- (UIImage *)getCurrentScreenShot {
    UIWindow *screenWindow = [UIApplication sharedApplication].keyWindow;
    UIGraphicsBeginImageContextWithOptions(screenWindow.frame.size, NO, [UIScreen mainScreen].scale);
    [screenWindow drawViewHierarchyInRect:screenWindow.frame afterScreenUpdates:YES];
    UIImage *viewImage = UIGraphicsGetImageFromCurrentImageContext();
    UIGraphicsEndImageContext();
    return viewImage;
}
</code></pre>
<p>用<code>UIImageToMat</code>将UIImage转成OpenCV中使用的格式<code>cv::Mat</code></p>
<h5 id="4定位棋子的位置">4.定位棋子的位置</h5>
<p>OpenCV的<code>matchTemplate</code>方法可以根据模板图片查找在对应的目标图片中的位置，正好符合我们的需求，我们先截取一个棋子的模板文件</p>
<figure data-type="image" tabindex="2"><img src="https://duzexu.github.io/post-images/1597660641561.jpg" alt="" loading="lazy"></figure>
<p>放入<code>Assert</code>文件夹下的<code>Resource</code>文件夹下，初始化相应的资源文件传入，获得棋子的位置</p>
<pre><code>- (CvPoint)chess_Loc:(cv::Mat)res tempImage:(cv::Mat)temp result:(cv::Mat)result {
    cv::matchTemplate(res, temp, result, CV_TM_SQDIFF);
    double minVal,maxVal;
    CvPoint minLoc,maxLoc,matchLoc;
    IplImage image = IplImage(result);
    cvMinMaxLoc(&amp;image,&amp;minVal,&amp;maxVal,&amp;minLoc,&amp;maxLoc,NULL);
    matchLoc = minLoc; //matchLoc是最佳匹配的区域左上角点
    chessRect = cvRect(matchLoc.x, matchLoc.y, temp.cols, temp.rows);
    //标记出棋子的位置
    cv::rectangle(res, cvRect(matchLoc.x, matchLoc.y, temp.cols, temp.rows), cvScalar(225,225,0));
    return cvPoint(matchLoc.x+temp.cols*0.5,matchLoc.y+temp.rows);
}
</code></pre>
<p>这步完成我们可以运行测试下，将结果转成<code>UIImage</code>存入相册看下棋子的位置是够正确</p>
<figure data-type="image" tabindex="3"><img src="https://duzexu.github.io/post-images/1597661194726.JPG" alt="" loading="lazy"></figure>
<h5 id="5获得下一步的位置">5.获得下一步的位置</h5>
<p>查找下一步位置的关键就是找出下一个方块的位置，我们暂且认为方块的上尖的位置就是下一个方块的位置，关键的方法是边缘检测函数<code>Canny</code></p>
<ul>
<li>先用<code>cvtColor</code>将图片转化为灰度图</li>
<li>边缘检测前用高斯模糊<code>GaussianBlur</code>处理下，方便边缘检测</li>
<li><code>Canny</code>函数进行边缘检测</li>
</ul>
<p>我们注意到由于下一步的位置距离上一个位置较近时可能会影响棋子的边缘可能会影响到下一步的位置判断，所以我们根据上一步棋子的位置将它的像素改为0</p>
<pre><code>cv::rectangle(res, chessRect, cvScalar(0), -1);
</code></pre>
<p>由于有效的部分是图片的中间部分，所以我们只处理高度为0.25到0.6之间的部分</p>
<p>根据棋子的位置确定查找的范围，进行行扫描，扫描到的第一个值为255的即返回当前坐标值</p>
<p>实验中发现椭圆形的上尖是条直线，所以我们要获取第一行连续值是255的x值的中点</p>
<pre><code>- (CvPoint)nextStep_Loc:(cv::Mat)res chessPoint:(CvPoint)point {
    cvtColor(res, res, CV_BGR2GRAY);
    cv::GaussianBlur(res,res,cvSize(3,3),0);
    cv::Canny(res, res, 3, 9);
    cv::rectangle(res, chessRect, cvScalar(0), -1);
    int minX = 0,maxX = 0;
    int x = 0,y = 0;
    if (point.x &lt; res.cols/2.0) {
        for (int j = res.rows*0.25; j &lt; res.rows*0.6; j++) {
            uchar* ptr = res.ptr&lt;uchar&gt;(j);
            for (int i = res.cols/3.0; i &lt; res.cols; i++) {
                if (ptr[i] == 255) {
                    if (minX == 0) {
                        minX = i;
                    }
                }else{
                    if (minX != 0 &amp;&amp; maxX == 0) {
                        maxX = i;
                        x = (int)((maxX-minX)/2.0)+minX;
                        y = j;
                        return cvPoint(x, y);
                    }
                }
            }
        }
    }else{
        for (int j = res.rows*0.25; j &lt; res.rows*0.6; j++) {
            uchar* ptr = res.ptr&lt;uchar&gt;(j);
            for (int i = 0; i &lt; res.cols/3.0*2.0; i++) {
                if (ptr[i] == 255) {
                    if (minX == 0) {
                        minX = i;
                    }
                }else{
                    if (minX != 0 &amp;&amp; maxX == 0) {
                        maxX = i;
                        x = (int)((maxX-minX)/2.0)+minX;
                        y = j;
                        return cvPoint(x, y);
                    }
                }
            }
        }
    }
    return cvPoint(0, 0);
}
</code></pre>
<p>用<code>circle</code>函数在我们计算出的位置上画个圈，也保存到相册，验证下结果</p>
<figure data-type="image" tabindex="4"><img src="https://duzexu.github.io/post-images/1597661208775.JPG" alt="" loading="lazy"></figure>
<h5 id="6计算时间">6.计算时间</h5>
<p>根据上两部算出来的位置算出距离进而得出时间</p>
<pre><code>- (CGFloat)timeWithImage:(UIImage *)image {
    @autoreleasepool {
        cv::Mat s;
        UIImageToMat(image, s);
        cv::Mat r = s.clone();
        CvPoint p = [self chess_Loc:s tempImage:chess result:r];
        CvPoint n = [self nextStep_Loc:s chessPoint:p];
        s.release();
        r.release();
        if (n.x != 0&amp;&amp;n.y != 0) {
            double distance = [self distanceBetweenPointA:p pointB:cvPoint(n.x, n.y)];
            return distance*coefficient/1000.0;
        }else{
            return 0.3;
        }
    }
}
</code></pre>
<h5 id="7操作按压">7.操作按压</h5>
<p>随机一个屏幕下部分的点，用<code>FTFakeTouch</code>的<code>longPressAtPoint:duration:</code>实现长按</p>
<pre><code>CGFloat x = (int)(randomRect.origin.x + (arc4random() % (int)randomRect.size.width));
                    CGFloat y = (int)(randomRect.origin.y + (arc4random() % (int)randomRect.size.height));
                    [[FTFakeTouch sharedInstance] longPressAtPoint:CGPointMake(x, y) duration:time];
</code></pre>
<p>以上就实现了整个需求，大家可以根据自己的手机大小试验出自己的系数</p>
<p>完整代码详见<a href="https://github.com/duzexu/WeChatHelper">WeChatHelper</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[iOS中录制和截取Unity屏幕]]></title>
        <id>https://duzexu.github.io/post/Record_Screen_In_Unity/</id>
        <link href="https://duzexu.github.io/post/Record_Screen_In_Unity/">
        </link>
        <updated>2020-08-14T07:24:45.000Z</updated>
        <summary type="html"><![CDATA[<p>本文介绍如何在集成Unity的iOS原生项目中截取和录制屏幕</p>
]]></summary>
        <content type="html"><![CDATA[<p>本文介绍如何在集成Unity的iOS原生项目中截取和录制屏幕</p>
<!-- more -->
<p>完整代码请查看<a href="https://github.com/duzexu/Record_Screen_In_Unity.git">Record_Screen_In_Unity</a></p>
<p>由于Unity不熟练，不知道怎么直接在Unity里录制屏幕。查询网上的方法，基本都是采用Unity的插件录制，不过基本都是收费插件，所以我们采用曲线救国，自己制作录制脚本。</p>
<p>思路是首先在Unity里获取当前屏幕截图，传给native,原生使用GPUImage进行视频的合成</p>
<h3 id="1-准备工作">1. 准备工作</h3>
<p>新建一个Unity和原生混合的工程（参考之前的<a href="https://github.com/duzexu/Use-Unity-as-Library.git">文章</a>），在主场景中放置一个白色的球，方便我们录制时验证</p>
<h3 id="2-unity端">2. Unity端</h3>
<ul>
<li>获取AR摄像头采集的原始数据</li>
</ul>
<p>使用<code>ARCameraManager</code>的<code>TryGetLatestImage</code>方法获取<code>XRCameraImage</code>对象，再用<code>XRCameraImageConversionParams</code>把数据转成需要的格式</p>
<pre><code>cameraManager.TryGetLatestImage(out XRCameraImage image)

renderTexture = new Texture2D(image.width, image.height, TextureFormat.BGRA32, false);
conversionParams = new XRCameraImageConversionParams(image, TextureFormat.BGRA32, CameraImageTransformation.None);
intPtr = new IntPtr(renderTexture.GetRawTextureData&lt;byte&gt;().GetUnsafePtr());

var rawTextureData = renderTexture.GetRawTextureData&lt;byte&gt;();
try
{
    image.Convert(conversionParams, intPtr, rawTextureData.Length);
}
finally
{
    image.Dispose();
}

renderTexture.Apply();

NativeAPI.SendVideoData(renderTexture.GetRawTextureData(), rawTextureData.Length);
</code></pre>
<ul>
<li>获取屏幕渲染结果</li>
</ul>
<p>使用<code>Texture2D</code>的<code>ReadPixels</code>获取屏幕渲染结果</p>
<pre><code>renderTexture.ReadPixels(new Rect(0, 0, Screen.width, Screen.height), 0, 0);
renderTexture.Apply();

byte[] rawData = renderTexture.GetRawTextureData();
NativeAPI.SendVideoData(rawData, rawData.Length);
</code></pre>
<h3 id="3-native端">3. Native端</h3>
<p>使用<code>GPUImageRawDataInput</code>作为输入，<code>GPUImageMovieWriter</code>作为输出<br>
摄像头数据是旋转的，添加<code>GPUImageTransformFilter</code>旋转回来<br>
如果不是录制全屏，添加<code>GPUImageCropFilter</code>截取屏幕的某一部分</p>
<p><strong><code>注意:</code></strong> 初始化GPUImageMovieWriter注意宽高需要是16的倍数，否则会有黑边</p>
<h3 id="4-音频录制">4. 音频录制</h3>
<p>通过<code>OnAudioFilterRead(float[] data, int channels)</code>采集unity的声音传给Native端，在Native端将音频数据转为<code>CMSampleBuffer</code>塞入GPUImage</p>
<p>Unity设置的音频采样率要和Native端统一</p>
<pre><code>AudioSettings.outputSampleRate = 44100;
</code></pre>
<p><strong><code>注意:</code></strong> <code>OnAudioFilterRead</code>方法只有在添加了<code>AudioSource</code>组件后才会回调，并且AudioSource的<code>playOnAwake</code>需要为<code>false</code></p>
<p>完整代码请查看<a href="https://github.com/duzexu/Record_Screen_In_Unity.git">Record_Screen_In_Unity</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[奇技淫巧给AR背景添加滤镜]]></title>
        <id>https://duzexu.github.io/post/Add_Filter_To_ARKit/</id>
        <link href="https://duzexu.github.io/post/Add_Filter_To_ARKit/">
        </link>
        <updated>2020-07-23T04:04:37.000Z</updated>
        <summary type="html"><![CDATA[<p>ARKit是苹果在2017年推出的AR开发平台，开发人员可以使用这套工具iPhone和iPad创建增强现实应用程序。</p>
<p>本文以ARKit提供的<code>ARSCNView</code>为例实现给AR背景添加滤镜。</p>
]]></summary>
        <content type="html"><![CDATA[<p>ARKit是苹果在2017年推出的AR开发平台，开发人员可以使用这套工具iPhone和iPad创建增强现实应用程序。</p>
<p>本文以ARKit提供的<code>ARSCNView</code>为例实现给AR背景添加滤镜。</p>
<!-- more -->
<p>先放代码 <a href="https://github.com/duzexu/Add-Filter-To-ARKit.git">Add Filter To ARKit</a></p>
<p>平常开发主要使用ARKit中的<code>ARSCNView</code>，或者使用iOS13新推出的<code>RealityKit</code>，当然也可以使用Metal或者OpenGL自己渲染。如果是自己渲染，整个的渲染过程都是自己控制的，可以方便的添加滤镜，但是需要繁琐的渲染代码和3D数学知识。使用系统提供的控件，好处是我们不需要关注渲染的过程和控制摄像机的运动，只需要关注业务逻辑，但是系统并没有给我们暴露自定义渲染的方法。</p>
<h3 id="思路">思路</h3>
<p>我们知道<code>ARSession</code>这个类是ARKit的核心，他负责摄像头数据的采集，分析，和处理，从硬件中读取手机姿态等信息，综合所有结果，在你的现实世界和创建的虚拟世界之间创建一个对应的关系，从而构建出一个AR世界。</p>
<p>我们从<code>ARSession</code>入手查找发现<code>ARSessionDelegate</code>有一个方法</p>
<pre><code>/**
 This is called when a new frame has been updated.
 
 @param session The session being run.
 @param frame The frame that has been updated.
 */
optional func session(_ session: ARSession, didUpdate frame: ARFrame)
</code></pre>
<p>这个方法会在每次有新<code>ARFrame</code>都会回调，查看<code>ARFrame</code>的<code>capturedImage</code>是记录每次摄像机采集的画面，那我们猜测每次<code>ARSession</code>处理完会传给<code>ARSCNView</code>，<code>ARSCNView</code>获取<code>ARFrame</code>的<code>capturedImage</code>来渲染，如果可以在系统获取<code>capturedImage</code>之前修改为添加滤镜后的数据，那系统就会渲染添加滤镜后的结果。</p>
<h3 id="验证">验证</h3>
<p>我们新建<code>ARSession</code>的<code>Extension</code>，在<code>+(void)load</code>方法中交换系统的<code>-(ARFrame *)currentFrame()</code>为<code>-(ARFrame *)_currentFrame()</code>方法，在<code>-(ARFrame *)_currentFrame()</code>中返回原始内容，运行后在这个方法中添加断点</p>
<figure data-type="image" tabindex="1"><img src="https://duzexu.github.io/post-images/1595561792446.jpg" alt="" loading="lazy"></figure>
<p>查看调用的方法为<code>-[ARSCNView _renderer:updateAtTime:]</code>,看方法名像是渲染的方法<br>
在<code>-(ARFrame *)_currentFrame()</code>中将<code>capturedImage</code>的所有内存数据设置为0，重新运行，发现屏幕为黑屏，验证了我们的猜测</p>
<h3 id="实践">实践</h3>
<p>我们使用<code>GPUImage</code>来处理<code>capturedImage</code>，建立一个<code>GPUImageFilterPipeline</code>，输入为<code>GPUImageMovie</code>，用来接收<code>capturedImage</code>的<code>CVPixelBuffer</code>数据，输出为<code>GPUImageFilter</code>，用来输出处理完的数据，因为是异步处理的，所以我们添加一个<code>DispatchSemaphore</code>锁，等待<code>GPUImage</code>处理完，处理完后将数据复制回<code>capturedImage</code></p>
<pre><code> let output = GPUImageFilter()
 
 pipeline = GPUImageFilterPipeline(orderedFilters: [], input: input, output: output)
 
 output.frameProcessingCompletionBlock = { [weak self] (output, time) -&gt; Void  in
     let frameBuffer = output?.framebufferForOutput()
     
     guard let buffer = frameBuffer else {
         return;
     }
     
     glFinish()
     
     self?.rgbBuffer = buffer.getRenderTarget()?.takeUnretainedValue()
     
     self?.semaphore.signal()
 }
</code></pre>
<p>运行后发现崩溃了，查找原因发现<code>capturedImage</code>的<code>CVPixelBuffer</code>格式是yuv的，而<code>GPUImage</code>处理完的数据为rgb的，所以我们添加<code>libyuv</code>库，把<code>GPUImage</code>处理完的rgb数据转成yuv，在复制回<code>capturedImage</code></p>
<pre><code>CVPixelBufferLockBaseAddress(pixelBuffer, [])
let final_y_buffer = CVPixelBufferGetBaseAddressOfPlane(pixelBuffer, 0)?.assumingMemoryBound(to: uint8.self);
let final_uv_buffer = CVPixelBufferGetBaseAddressOfPlane(pixelBuffer, 1)?.assumingMemoryBound(to: uint8.self);
input.processMovieFrame(pixelBuffer, withSampleTime: .zero)
_ = semaphore.wait(timeout: .distantFuture)
CVPixelBufferLockBaseAddress(rgbBuffer!, [])
let width = CVPixelBufferGetWidth(rgbBuffer!)
let height = CVPixelBufferGetHeight(rgbBuffer!)
let rgbAddress = CVPixelBufferGetBaseAddress(rgbBuffer!)?.assumingMemoryBound(to: uint8.self)
ARGBToNV12(rgbAddress, Int32(width*4), final_y_buffer, Int32(width), final_uv_buffer, Int32(width), Int32(width), Int32(height))
CVPixelBufferUnlockBaseAddress(rgbBuffer!, [])
CVPixelBufferUnlockBaseAddress(pixelBuffer, [])
</code></pre>
<p>这样我们就可以随意在<code>GPUImageFilterPipeline</code>添加或删除滤镜了</p>
<p>测试后发现如果滤镜切换特别快会有随机崩溃，猜测是切换过程影响到最后的数据，修改为等待上一帧处理完再切换滤镜</p>
<h3 id="总结">总结</h3>
<p>本文通过比较取巧的方式实现了这个需求，有点不走寻常路。采用Unity等现成的渲染引擎会是一个相对稳妥的方案，集成也很简单（参考之前的文章 <a href="https://github.com/duzexu/Use-Unity-as-Library.git">Use Unity as Library</a>），直接给摄像机添加滤镜脚本就行了</p>
<p>查看全部代码请点击 <a href="https://github.com/duzexu/Add-Filter-To-ARKit.git">Add Filter To ARKit</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[将Unity以库形式集成到原生iOS]]></title>
        <id>https://duzexu.github.io/post/Use_Unity_as_Library/</id>
        <link href="https://duzexu.github.io/post/Use_Unity_as_Library/">
        </link>
        <updated>2020-05-20T10:20:06.000Z</updated>
        <summary type="html"><![CDATA[<p>Unity 2019.3及之后的版本将添加支持，可以将Unity作为原生Android和iOS应用控制的库，以便轻松加入AR和其它Unity功能。</p>
<p>这意味着开发者可以将Unity所能实现的增强现实AR、3D/2D实时渲染、2D迷你游戏等功能，直接添加到自己的原生移动应用。</p>
]]></summary>
        <content type="html"><![CDATA[<p>Unity 2019.3及之后的版本将添加支持，可以将Unity作为原生Android和iOS应用控制的库，以便轻松加入AR和其它Unity功能。</p>
<p>这意味着开发者可以将Unity所能实现的增强现实AR、3D/2D实时渲染、2D迷你游戏等功能，直接添加到自己的原生移动应用。</p>
<!-- more -->
<p>直接上代码 <a href="https://github.com/duzexu/Use-Unity-as-Library.git">Use Unity as Library</a></p>
<h2 id="限制">限制</h2>
<ul>
<li>作为库使用的Unity仅支持全屏渲染，不支持在屏幕的一部分进行渲染。</li>
<li>不支持加载多个Unity运行时实例。</li>
<li>开发者需要调整第三方插件，包括原生插件和托管插件，从而让它们正常工作。</li>
</ul>
<h2 id="集成要求">集成要求</h2>
<ul>
<li>Xcode 9.4以上版本</li>
<li>Unity 2019.3.a2以上版本</li>
</ul>
<h2 id="集成步骤">集成步骤</h2>
<h4 id="1下载示例工程">1.下载示例工程</h4>
<ul>
<li>克隆或下载 <a href="https://github.com/Unity-Technologies/uaal-example">Demo</a> 这包含<br>
<img src="https://duzexu.github.io/post-images/1589971003144.png" alt="" loading="lazy">
<ul>
<li>UnityProject-这是Unity示例工程，其中包含了几个简单的交互，我们要将他集成进原生工程。Assets/Plugins/iOS 中的文件，用于Unity与原生应用进行通信</li>
<li>NativeiOSApp-这是简单的iOS原生应用，我们要在其中集成Unity项目。使用UnityFrameworkLoad()加载Unity引擎</li>
</ul>
</li>
</ul>
<h4 id="2导出unity为xcode项目">2.导出Unity为Xcode项目</h4>
<p>无需特别设置，正常生成Xcode项目</p>
<ul>
<li>从Unity编辑器中打开UnityProject</li>
<li>删除或更新广告软件包至v3.*（2.0.8版本与作为库的Unity不兼容）（Menu/Window/Package Manager）</li>
<li>选择并切换到平台iOS（Menu/File/Builds Settings）</li>
<li>点击Build，选择导出文件夹UnityProject/Build,点击构建</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://duzexu.github.io/post-images/1589972003675.png" alt="" loading="lazy"></figure>
<h4 id="3设置xcode-workspace">3.设置Xcode workspace</h4>
<p>使用Xcode workspace将原生项目和导出的项目集成到一起</p>
<ul>
<li>新建Untitled.workspace保存到根目录下 （File/New/Workspace）</li>
<li>点击左下角的加号添加NativeiOSApp.xcodeproj和第二步生成的Unity-iPhone.xcodeproj（File / Add Files to &quot;Untitled&quot;）<br>
<img src="https://duzexu.github.io/post-images/1590041804021.png" alt="" loading="lazy"></li>
</ul>
<h4 id="4添加unityframeworkframework">4.添加UnityFramework.framework</h4>
<p>这个步骤把Unity的工程已framework的形式集成进NativeiOSApp，不需要改变NativeiOSApp的结构</p>
<ul>
<li>在NativeiOSApp中选择NativeiOSApp target</li>
<li>在Build Phases/ Embedded Binaries栏目中点击+</li>
<li>选择Unity-iPhone/Products/UnityFramework.framework</li>
<li>在Build Phases/Linked Frameworks and Libraries中移除UnityFramework.framework<br>
<img src="https://duzexu.github.io/post-images/1590042730744.png" alt="" loading="lazy"></li>
</ul>
<h4 id="5暴露nativecallproxyh">5.暴露NativeCallProxy.h</h4>
<p>这个文件是Unity和原生项目接口的定义</p>
<ul>
<li>选择Unity-iPhone / Libraries / Plugins / iOS / NativeCallProxy.h</li>
<li>在Inspector/Target Membership中选择UnityFramework并设置为Public<br>
<img src="https://duzexu.github.io/post-images/1590043415570.png" alt="" loading="lazy"></li>
</ul>
<h4 id="6暴露data文件夹">6.暴露Data文件夹</h4>
<p>默认Data文件是属于Unity-iPhone target，我们要将他暴露给framework</p>
<ul>
<li>选择Unity-iPhone/Data文件夹</li>
<li>在Inspector/Target Membership中选择UnityFramework<br>
<img src="https://duzexu.github.io/post-images/1590044436630.png" alt="" loading="lazy"></li>
</ul>
<p>如果顺利，现在就可以成功的运行NativeiOSApp了</p>
<h2 id="swift集成">Swift集成</h2>
<p>原生Swift集成过程跟OC的一样，只不过NativeCallProxy的实现需要桥接文件。在桥接文件中引入</p>
<pre><code>#import &lt;UnityFramework/NativeCallProxy.h&gt;
</code></pre>
<p>我新建了一个UnitySwiftMix.workspace Demo演示如何在Swift中集成，并封装了Unity Framework的接口，同时这个工程也集成了Pod</p>
<p>详情请点击 <a href="https://github.com/duzexu/Use-Unity-as-Library.git">Use Unity as Library</a></p>
<h2 id="参考">参考</h2>
<p><a href="https://connect.unity.com/p/zai-yuan-sheng-ioshuo-androidying-yong-zhong-jiang-unityzuo-wei-ku-shi-yong">在原生iOS或Android应用中将Unity作为库使用</a></p>
<p><a href="https://forum.unity.com/threads/integration-unity-as-a-library-in-native-ios-app.685219/">Integration Unity as a library in native iOS app</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://duzexu.github.io/post/hello-gridea/</id>
        <link href="https://duzexu.github.io/post/hello-gridea/">
        </link>
        <updated>2018-12-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea 主页</a><br>
<a href="https://fehey.com/">示例网站</a></p>
<h2 id="特性">特性👇</h2>
<p>📝  你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️  你可以对文章进行标签分组</p>
<p>📋  你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻  你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎  你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬  你可以进行简单的配置，接入 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 或 <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> 评论系统</p>
<p>🇬🇧  你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>